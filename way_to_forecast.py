# -*- coding: utf-8 -*-
"""way_to_forecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VChnYf42Sf-gYzJXTh-yNoCy0M9AWr1g
"""

import random
import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
import statsmodels.api as sm

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error
from statsmodels.tsa.stattools import pacf
from statsmodels.tsa.stattools import acf

from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.stats.diagnostic import het_breuschpagan
from statsmodels.stats.diagnostic import kstest_normal

from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf

from sklearn.preprocessing import StandardScaler

from math import sqrt
from math import floor
from scipy import stats
from datetime import date
from datetime import datetime

from itertools import product
from itertools import groupby

!pip install arch
from arch import arch_model

def readYfData(idx):
  start_date = datetime(2016, 1, 1)
  end_date   = date.today()
  etf_df = yf.download(idx, start=start_date, end=end_date)
  return etf_df

def computeReturns(prices):
  diffs   = np.diff(prices).tolist()
  prices  = np.delete(prices, len(prices) - 1).tolist()
  returns = [round(a / b, 5) for a,b in zip(diffs, prices)]
  returns = [0.00000] + returns
  return returns

def computeRsi(returns):
  up_close   = len(list(filter(lambda x: (x > 0), returns)))
  down_close = len(list(filter(lambda x: (x < 0), returns)))
  if down_close == 0:
    down_close = 1
  rs_val = round(up_close / down_close, 2)
  rsi    = round(100 - (100 / (1 + rs_val)), 2)
  return rsi

def computeRsiList(returns, burn_in, look_back):
  rsi = []
  first_rsi = 0.0
  for day in range(burn_in, len(returns)):
    ytd_returns = returns[0:day]
    day_rsi = computeRsi(ytd_returns[len(ytd_returns) - look_back:len(ytd_returns)])
    rsi.append(day_rsi)
    if day == burn_in:
      first_rsi == day_rsi
  if first_rsi >= 80:
    first_rsi = 50
  elif first_rsi <= 20:
    first_rsi = 50
  prefix_rsi = [first_rsi for x in range(burn_in)]
  res = prefix_rsi + rsi
  return res

def removeOutliers(returns, sigma_limit):
  scaler = StandardScaler()
  scaled_log_returns = scaler.fit_transform(np.array(returns).reshape(-1, 1))
  scaled_outliers = [i for i, x in enumerate(scaled_log_returns)\
                     if abs(x) > sigma_limit]
  rep = np.median(returns)
  log_returns = [rep if i in scaled_outliers else x for\
                 i, x in enumerate(returns)]
  return log_returns

def computeAcfValue(diffs, n_lags):
  acf_res = pd.DataFrame(acf(pd.Series(diffs), nlags=n_lags))
  acf_res.columns = ['value']
  # ACF confidence interval is not equal to the marked region of the ACF plot
  # since the region is the critical region and it is computed differently from
  # the confidence interval. Source:
  # https://stats.stackexchange.com/questions/185425/how-to-determine-the-critical-values-of-acf
  # formula: 1.96 / sqrt(T - d), where T -- number of observations, d - lag
  critical_region = []
  for lag in range(1, n_lags + 2):
    critical_region.append(np.round(1.96 / np.sqrt(len(diffs) - lag), 5))
  acf_res['region'] = critical_region
  acf_res['abs_val'] = abs(acf_res['value'])
  acf_res = acf_res[acf_res.index != 0]
  signif_idx = acf_res.index[acf_res['abs_val'] >= acf_res['region']].tolist()
  if len(signif_idx) > 0:
    idx_list = [1 if x in signif_idx else 0 for x in range(1, max(signif_idx) + 1)]
  else:
    idx_list = [0]
  idx_list   = tuple(idx_list)
  return idx_list

def computePacfValue(diffs, n_lags):
  pacf_res = pd.DataFrame(pacf(pd.Series(diffs), nlags=n_lags))
  pacf_res.columns = ['value']
  critical_region  = []
  for lag in range(1, n_lags + 2):
    critical_region.append(np.round(1.96 / np.sqrt(len(diffs) - lag), 5))
  pacf_res['region']  = critical_region
  pacf_res['abs_val'] = abs(pacf_res['value'])
  pacf_res = pacf_res[pacf_res.index != 0]
  signif_idx = pacf_res.index[pacf_res['abs_val'] >= pacf_res['region']].tolist()
  if len(signif_idx) > 0:
    idx_list = [1 if x in signif_idx else 0 for x in range(1, max(signif_idx) + 1)]
  else:
    idx_list = [0]
  idx_list   = tuple(idx_list)
  return idx_list


def findAcfValue(acf_val):
  """
  This function takes a sequence of ACF lags starting from 1 and up to n-lags to
  return the number of lags as a list of indices that are equal to 1. In case
  the length of the ACF is 1, then it just returns the first value.
  """
  new_acf = 0
  if len(acf_val) == 1:
    new_acf = acf_val[0]
  else:
    new_acf = [i + 1 for i,x in enumerate(acf_val) if x == 1]
  return new_acf

def predictArch(training, testing):
  """
  This function takes training data and fits GARCH or HARCH model. If p-values
  are below 0.05, then the model is used to forecast the returns for the next
  n-days ahead (n-days = length of testing data). The mean error of the forecast
  is computed and compared to the mean error of naive forecast. If the model is
  better than the naive forecast, then it is used for predictions. Otherwise,
  the naive forecast is used. The function returns the following list of params:
  - list of predicted values
  - dictionary:
      - mae of the model
      - mae of naive forecast
      - model precision
      - actual positive in test set
  """
  scaler = StandardScaler()
  scaled_training = scaler.fit_transform(np.array(training).reshape(-1, 1))
  scaled_testing  = scaler.transform(np.array(testing).reshape(-1, 1))
  model = arch_model(scaled_training, mean='zero', vol='garch', p=3, q=3, dist='normal')
  res = model.fit(update_freq=100, disp=False)

  pred_horizon = len(testing)
  preds = res.forecast(horizon=pred_horizon, method='simulation')
  y_hat = preds.variance

  y_hat = scaler.inverse_transform(y_hat).tolist()[0]
  # y_hat = np.exp(y_hat).tolist() in case we want not log returns but actual returns
  y_naive = [0 for x in range(7)]

  mae_model = mean_absolute_error(testing, y_hat)
  mae_naive = mean_absolute_error(testing, y_naive)

  testing_signs = [1 if x >= 0 else 0 for x in testing]
  yhat_signs    = [1 if x >= 0 else 0 for x in y_hat]
  model_precision = precision_score(testing_signs, yhat_signs)

  actual_positive = np.sum(testing_signs)

  result = {'mae model': mae_model,
            'mae naive': mae_naive,
            'precision': model_precision,
            'positives': actual_positive,
            'step': 0}
  return y_hat, result

iuit_l = readYfData('IUIT.L')

# Define constants to control trading
ENTRY_POINT =   21.559999 # Price of 19-11-2021 when we started trading
ENTRY_IDX   = 1489        # Index of 19-11-2021 when we started trading
LOOK_BACK   = 1000        # Number of days to look back when building a model
LOOK_AHEAD  =    7        # Number of days to forecast ahead
BURN_IN     =   30        # Burn in period to allow RSI to stabilize
OUTLIER_SIG =  3.3        # Outlier sigma to cut-off outliers
INITIAL_INV = 1000        # Initial investment amount
TRANS_COST  =    8        # Cost per one transaction
IDLE_COST   =  120        # Cost if now transactions in 365 days
MIN_PURCHAS =   10        # Minimal number of stocks to buy in a batch

prices      = iuit_l['Close'].tolist()
log_prices  = np.log(prices).tolist()
returns     = computeReturns(log_prices)
price_trend = pd.Series(prices).rolling(100).mean()

# We use standardized log returns to detect outliers since other methods like
# IQR are too sensitive to outliers and identify too many of them in the series
# which might lead to loosing some valuable information.
returns = removeOutliers(returns, OUTLIER_SIG)
n_steps  = len(returns) - (ENTRY_IDX + LOOK_AHEAD)
last_idx = len(returns) + 1 - LOOK_AHEAD

# Log return plot demostrates changing variance meaning that ARIMA model or its
# variations AR or MA are not suitable for this time series forecasting. We
# must try GARCH or ARCH models instead.
plt.plot(returns, color='lightgrey')
plt.show()

steps = 0
testing_history  = []
forecast_history = []
result_history   = []

for step in range(ENTRY_IDX, last_idx):
  window_start = step - LOOK_BACK
  window_end   = step + LOOK_AHEAD
  window_rets = returns[window_start:window_end]
  training = window_rets[:LOOK_BACK]
  testing  = window_rets[LOOK_BACK:]
  preds, result = predictArch(training, testing)
  result['step'] = step
  result_history.append(result)
  testing_history.extend(testing)
  forecast_history.extend(preds)
  steps += 1
  #if steps == 100:
  #  break

plt.plot(testing_history, color='lightgrey')
plt.plot(forecast_history, color='green')
plt.show()

results = pd.DataFrame(result_history)
results.head()

plt.plot(results['mae naive'], color='lightgrey')
plt.plot(results['mae model'], color='green')
plt.show()

plt.plot(results['precision'], color='darkseagreen')
plt.show()